{"title":"Log Timing Delays in Splunk Could be Putting Your Security at Risk","markdown":{"yaml":{"title":"Log Timing Delays in Splunk Could be Putting Your Security at Risk","author":"Michael McKinley","date":"2023-04-18","format":{"html":{"code-fold":true,"page-layout":"full"}}},"headingText":"A Tale of Two Times","containsRefs":false,"markdown":"\n\n**BLUF:** Logging delay to Splunk as little as 100ms can cause alerts to be missed. This post talks about this issue, detection, and offers a solution.\n\nSplunk is a powerful platform for collecting, indexing, and analyzing data from various sources. However, it is critically important to understand the nuances of how Splunk handles time; forgoing such consideration may lead to missing critical events. \n\n#### _time\nThe `_time` field in Splunk represents the timestamp of an event as specified by the source log. This field is critical for time-based analysis, such as identifying trends, detecting anomalies, and correlating events across different sources. This is the time that is visualized by Splunk when viewing search results, and is used as the time variable when performing searches.\n\n#### _indextime\nThe `_indextime` field in Splunk represents the timestamp when the event is indexed by Splunk, which may not always be the same as the `_time` field. Simply, this is the time Splunk logged the event, the time it becomes avaiable in search, and it will almost always differ from `_time`, even if by miliseconds. \n\n### A Wrinkle in Time\n\nWhy do the times differ? \n\nTruth is, there is delay, there are many points in the ingestion pipeline that can cause delay such as:\n* Network latency\n* Logging throughput capacity\n* Logging interval \n* Clock skew\n\nThe issue with timing delays in Splunk is that it can cause alerts to be missed, which can have serious consequences for security and other critical operations. \n\nFor instance, if an alert is monitoring a critical system, but there is a delay between the `_time` and `_indextime` timestamps, **the alert may not be triggered even when events occur.**\n\n### Small Delay = Big Problem\n\nHow much delay can cause events to be missed? \n\nThis is a question that many previous discussions on this topic fail to address. While many may note delays of days, hours, or minutes, causing issue; it is important to note that **delays of milliseconds can result in missed events**. In testing, delays as little as 100ms resulted in missed events, and theoretically, the number may even be lower. This raises an important question - are you confident that all of your critical logging sources consistently log in near real-time?\n\n### Delay Detection\n\n**Can I calculate delays in my log sources?**\n\nYes, Splunk has a great article on this: [here](https://docs.splunk.com/Documentation/Splunk/9.0.4/Troubleshooting/Troubleshootingeventsindexingdelay). \n\nTL;DR To discover log delays subtract `_time` from `_indextime`.\n\n`index=example_delay | eval delay_sec=_indextime-_time | eval delay_minute=(delay_sec/60) | timechart span=1h avg(delay_minute) by index`\n\n![](splunk_blog_1.png \"Fig 1. Example Timechart for Splunk Search\")\n_Fig 1. Example Timechart for Splunk Search_\n\n**Can I discover if any of my recent saved searches missed events?**\n\nYes, a simple method is to re-run the same search and compare the results, if the results differ over the same time period, there is likely a timing issue. \n\nBelow is an example script in python to identify saved searches with timing issues. For information on usage go: [here](#link).\nI've run this script against an lab instance of Splunk with intentially induced delays, the results are below. \n\n\n### A Solution\n\nRather than telling Splunk to alert to items within the last `_time` window for our searches, we can alert to anything indexed in the time period since our search last ran. This is instead saying, \"Splunk tell me about any log that you just discovered\". \n\nThe alert needs to be modified in two ways:\n\n1. Update the Alert Query\n2. Update the Time Window\n\n#### Update Alert Query\n\nSplunk can use time modifiers in the search query ([ref](https://docs.splunk.com/Documentation/SCS/current/Search/Timemodifiers)). To switch to `_indextime` alerting we will need to add `_index_earliest` and `_index_latest` to our search query. This will define the `_indexedtime` range we intend to search. \n\n`_index_earliest` - In most cases, this should be set to the time interval the alert looksback on. (e.g. `_index_earliest=-15m`) \\\n\n`_index_latest` - In most cases, this should be set to the current time. (e.g. `_index_latest=now()`)\n\n#### Update Time Window\n\nSwitching to `_indextime` alerting will not remove the use of `_time`; it is still a filter on the search. Instead, we need to set the `_time` window to the maximum delay we still want to alert on. \n\n#### An Example\n\nThe below search is updated to alert on `_indextime` alerting. The figure is marked relative to behavior referenced in the list:\n\n1. Search every 15 minutes\n2. Search everything indexed within the last 15 minutes \n3. Search everything with _time within the last 14 days*\n\n*This does not significantly impact processing, it is not the same as processing 14 days of data\n\n![](splunk_blog_2.png \"Fig 2. Example Updated Splunk Alert\") \n_Fig 2. Example Updated Splunk Alert_\n\nThis alerts runs every 15 minutes, searching logs indexed in the last 15 minutes, and searching logs that Splunk believes are up to 14 days delayed. \n\nSimply using `_time` can cause issues with saved searches, even in logs are delayed by minimal amounts. Switching to `_indextime` alerting reduces this problem significantly and I would recommend running all of the saved searches you can with this method. \n","srcMarkdownNoYaml":"\n\n### A Tale of Two Times\n**BLUF:** Logging delay to Splunk as little as 100ms can cause alerts to be missed. This post talks about this issue, detection, and offers a solution.\n\nSplunk is a powerful platform for collecting, indexing, and analyzing data from various sources. However, it is critically important to understand the nuances of how Splunk handles time; forgoing such consideration may lead to missing critical events. \n\n#### _time\nThe `_time` field in Splunk represents the timestamp of an event as specified by the source log. This field is critical for time-based analysis, such as identifying trends, detecting anomalies, and correlating events across different sources. This is the time that is visualized by Splunk when viewing search results, and is used as the time variable when performing searches.\n\n#### _indextime\nThe `_indextime` field in Splunk represents the timestamp when the event is indexed by Splunk, which may not always be the same as the `_time` field. Simply, this is the time Splunk logged the event, the time it becomes avaiable in search, and it will almost always differ from `_time`, even if by miliseconds. \n\n### A Wrinkle in Time\n\nWhy do the times differ? \n\nTruth is, there is delay, there are many points in the ingestion pipeline that can cause delay such as:\n* Network latency\n* Logging throughput capacity\n* Logging interval \n* Clock skew\n\nThe issue with timing delays in Splunk is that it can cause alerts to be missed, which can have serious consequences for security and other critical operations. \n\nFor instance, if an alert is monitoring a critical system, but there is a delay between the `_time` and `_indextime` timestamps, **the alert may not be triggered even when events occur.**\n\n### Small Delay = Big Problem\n\nHow much delay can cause events to be missed? \n\nThis is a question that many previous discussions on this topic fail to address. While many may note delays of days, hours, or minutes, causing issue; it is important to note that **delays of milliseconds can result in missed events**. In testing, delays as little as 100ms resulted in missed events, and theoretically, the number may even be lower. This raises an important question - are you confident that all of your critical logging sources consistently log in near real-time?\n\n### Delay Detection\n\n**Can I calculate delays in my log sources?**\n\nYes, Splunk has a great article on this: [here](https://docs.splunk.com/Documentation/Splunk/9.0.4/Troubleshooting/Troubleshootingeventsindexingdelay). \n\nTL;DR To discover log delays subtract `_time` from `_indextime`.\n\n`index=example_delay | eval delay_sec=_indextime-_time | eval delay_minute=(delay_sec/60) | timechart span=1h avg(delay_minute) by index`\n\n![](splunk_blog_1.png \"Fig 1. Example Timechart for Splunk Search\")\n_Fig 1. Example Timechart for Splunk Search_\n\n**Can I discover if any of my recent saved searches missed events?**\n\nYes, a simple method is to re-run the same search and compare the results, if the results differ over the same time period, there is likely a timing issue. \n\nBelow is an example script in python to identify saved searches with timing issues. For information on usage go: [here](#link).\nI've run this script against an lab instance of Splunk with intentially induced delays, the results are below. \n\n\n### A Solution\n\nRather than telling Splunk to alert to items within the last `_time` window for our searches, we can alert to anything indexed in the time period since our search last ran. This is instead saying, \"Splunk tell me about any log that you just discovered\". \n\nThe alert needs to be modified in two ways:\n\n1. Update the Alert Query\n2. Update the Time Window\n\n#### Update Alert Query\n\nSplunk can use time modifiers in the search query ([ref](https://docs.splunk.com/Documentation/SCS/current/Search/Timemodifiers)). To switch to `_indextime` alerting we will need to add `_index_earliest` and `_index_latest` to our search query. This will define the `_indexedtime` range we intend to search. \n\n`_index_earliest` - In most cases, this should be set to the time interval the alert looksback on. (e.g. `_index_earliest=-15m`) \\\n\n`_index_latest` - In most cases, this should be set to the current time. (e.g. `_index_latest=now()`)\n\n#### Update Time Window\n\nSwitching to `_indextime` alerting will not remove the use of `_time`; it is still a filter on the search. Instead, we need to set the `_time` window to the maximum delay we still want to alert on. \n\n#### An Example\n\nThe below search is updated to alert on `_indextime` alerting. The figure is marked relative to behavior referenced in the list:\n\n1. Search every 15 minutes\n2. Search everything indexed within the last 15 minutes \n3. Search everything with _time within the last 14 days*\n\n*This does not significantly impact processing, it is not the same as processing 14 days of data\n\n![](splunk_blog_2.png \"Fig 2. Example Updated Splunk Alert\") \n_Fig 2. Example Updated Splunk Alert_\n\nThis alerts runs every 15 minutes, searching logs indexed in the last 15 minutes, and searching logs that Splunk believes are up to 14 days delayed. \n\nSimply using `_time` can cause issues with saved searches, even in logs are delayed by minimal amounts. Switching to `_indextime` alerting reduces this problem significantly and I would recommend running all of the saved searches you can with this method. \n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"highlight-style":"github","output-file":"splunklogdelay.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Danger","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.287","resources":["CNAME"],"theme":{"dark":"../../../../assets/theme-dark.scss","light":"../../../../assets/theme-light.scss"},"smooth-scroll":true,"title-block-banner":true,"title":"Log Timing Delays in Splunk Could be Putting Your Security at Risk","author":"Michael McKinley","date":"2023-04-18","page-layout":"full"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}